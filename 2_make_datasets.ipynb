{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions needed to create the datasets from the raw generated data\n",
    "## Needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from copy import deepcopy\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions needed to build the dataset\n",
    "def list_files(parent_directory: str = \".\", extension: str = \".txt\") -> list:\n",
    "    \"\"\"List all files in parent and subdirectories with a specific extension.\n",
    "    \n",
    "    Args:\n",
    "        parent_directory (str, optional): parent directory. Defaults to \".\".\n",
    "        extension (str, optional): extension of the files to list. Defaults to \".txt\".\n",
    "    \n",
    "    Returns:\n",
    "        list: list of files with the specific extension\n",
    "    \"\"\"\n",
    "    files_list = []\n",
    "    for root, _, files in os.walk(parent_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                files_list.append(os.path.join(root, file))\n",
    "    return files_list\n",
    "\n",
    "\n",
    "def validate_line(line: str) -> bool:\n",
    "    \"\"\"Validate each line of the txt file to be a valid json\n",
    "\n",
    "    Args:\n",
    "        line (str): line of the txt file\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the line is a valid json, False otherwise\n",
    "    \"\"\"\n",
    "    try:        \n",
    "        # Add the brackets to make it a valid json\n",
    "        line = f\"[{line}]\"\n",
    "        \n",
    "        # Remove the last comma before the closing bracket\n",
    "        line = re.sub(r\"\\,\\s*\\]\", r\"]\", line, 1)\n",
    "\n",
    "        json.loads(line)\n",
    "        return True\n",
    "\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_json(filename: str) -> list:\n",
    "    \"\"\"Extract the json from the txt file\n",
    "    \n",
    "    Args:\n",
    "        filename (str): txt filename\n",
    "        \n",
    "    Returns:\n",
    "        list: list of json objects\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = text[max(text.find('['), 0):]\n",
    "\n",
    "        # Remove the </s> tag, [ and ] from the text\n",
    "        text = text.replace(r\"</s>\",\"\")\n",
    "        text = text.replace(r\"[\",\"\")\n",
    "        text = text.replace(r\"]\",\"\")\n",
    "        text = text.replace(r\"\\n\",\"\")\n",
    "        \n",
    "        # Remove malformed json elements\n",
    "        text = re.sub(r\"(\\}\\,\\s*\\w+\\s*\\{)\", r\"},\\n{\", text)\n",
    "        \n",
    "        # Only keep the valid json elements\n",
    "        text = filter(validate_line, text.split(\"\\n\"))\n",
    "        text = \"\\n\".join(text)\n",
    "        \n",
    "        # Add the brackets to make it a valid json\n",
    "        text = f\"[{text}]\"\n",
    "        \n",
    "        # Remove the last comma\n",
    "        text = re.sub(r\"\\,\\s*\\]\", r\"]\", text, 1)\n",
    "\n",
    "        return json.loads(text)\n",
    "\n",
    "\n",
    "def natural_sort(list_to_sort: list) -> list:\n",
    "    \"\"\"Sort a list of strings in natural order\n",
    "    \n",
    "    Args:\n",
    "        list_to_sort (list): list of strings to sort\n",
    "        \n",
    "    Returns:\n",
    "        list: sorted list\n",
    "    \"\"\"\n",
    "    def convert(text):\n",
    "        return int(text) if text.isdigit() else text.lower()\n",
    "    \n",
    "    def alphanumeric_key(key: str) -> list:\n",
    "        return [convert(character) for character in re.split('([0-9]+)', key)]\n",
    "\n",
    "    return sorted(list_to_sort.copy(), key=alphanumeric_key)\n",
    "\n",
    "\n",
    "def extract_dataset(dataset_files, tools):\n",
    "    dataset = []\n",
    "\n",
    "    for file in natural_sort(dataset_files):\n",
    "        dataset.append(extract_json(file))\n",
    "\n",
    "    new_dataset = []\n",
    "    for data, tool in zip(dataset, tools):\n",
    "        new_entry = tool\n",
    "        reference = tool['use_cases'][0]['user_request']\n",
    "        new_data = []\n",
    "        \n",
    "        for generation in data:\n",
    "            scored_generation = generation\n",
    "            user_request = scored_generation['user_request']\n",
    "            # print(rouge_score(user_request, reference))\n",
    "            scored_generation.update({\"rouge_score\": rouge_score(user_request, reference)})\n",
    "            new_data.append(scored_generation)\n",
    "\n",
    "        new_entry.update({\"dataset\": new_data})\n",
    "        new_dataset.append(new_entry)\n",
    "\n",
    "    return deepcopy(new_dataset)\n",
    "\n",
    "\n",
    "def make_json_file(data, filename: str) -> None:\n",
    "    \"\"\"Make a json file from the data\n",
    "    \n",
    "    Args:\n",
    "        data (list): data to write in the json file\n",
    "        filename (str): name of the json file\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=2)\n",
    "\n",
    "# Functions needed to evaluate the dataset\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "def rouge_score(generation, reference) -> float:\n",
    "    \"\"\"Compute the rouge score of a generation compared to a reference.\n",
    "    \n",
    "    Args:\n",
    "        generation (str): generated text\n",
    "        reference (str): reference text\n",
    "        \n",
    "    Returns:\n",
    "        float: rouge score\n",
    "    \"\"\"\n",
    "    return rouge_scorer.get_scores(\n",
    "        hyps=generation,\n",
    "        refs=reference,\n",
    "    )[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "\n",
    "def print_dataset_mean_rouge(dataset):\n",
    "    \"\"\"Print the mean rouge score of each class and the total mean rouge score.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): dataset to evaluate\n",
    "    \"\"\"\n",
    "    total_average_rouge_score = 0\n",
    "    total_number_of_generations = 0\n",
    "\n",
    "    for data in dataset:    \n",
    "        classe = data['dataset']\n",
    "        average_rouge_score = 0\n",
    "\n",
    "        for generation in classe:\n",
    "            average_rouge_score += generation['rouge_score']\n",
    "            \n",
    "        average_rouge_score /= len(classe)\n",
    "        total_average_rouge_score += average_rouge_score\n",
    "        total_number_of_generations += len(classe)\n",
    "        \n",
    "        print(\"Class:\", data['tool_name'], \"\\taverage ROUGE score:\", average_rouge_score)\n",
    "\n",
    "    total_average_rouge_score /= total_number_of_generations\n",
    "    print(\"Total average ROUGE score:\", total_average_rouge_score)\n",
    "\n",
    "\n",
    "def print_dataset_size(dataset):\n",
    "    \"\"\"Print the size of each class and the total size of the dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): dataset to evaluate\n",
    "    \"\"\"\n",
    "    total_number_of_elements = 0\n",
    "    total_per_class = {}\n",
    "\n",
    "    for data in dataset:    \n",
    "        classe = data['dataset']\n",
    "        total_per_class[data['tool_name']] = len(classe)\n",
    "        total_number_of_elements += len(classe)\n",
    "    \n",
    "    print(\"Total number of elements:\", total_number_of_elements)\n",
    "    print(total_per_class)\n",
    "    \n",
    "    # Compute mean\n",
    "    mean = total_number_of_elements / len(dataset)\n",
    "    print(\"Mean:\", mean)\n",
    "    \n",
    "    # Compute media\n",
    "    dataset_size = sorted(total_per_class.values())\n",
    "    if len(dataset_size) % 2 == 0:\n",
    "        median = (dataset_size[len(dataset_size) // 2] + dataset_size[len(dataset_size) // 2 - 1]) / 2\n",
    "    else:\n",
    "        median = dataset_size[len(dataset_size) // 2]\n",
    "        \n",
    "    print(\"Median:\", median)\n",
    "\n",
    "# Functions needed to automatically describe the dataset\n",
    "def lower_case_first_letter(string: str) -> str:\n",
    "    \"\"\"Lower case the first letter of a string.\n",
    "    \n",
    "    Args:\n",
    "        string (str): string to lower case\n",
    "    \n",
    "    Returns:\n",
    "        str: string with the first letter lower cased\n",
    "    \"\"\"\n",
    "    return string[0].lower() + string[1:]\n",
    "\n",
    "\n",
    "def create_an_enumeration(list_of_strings: list) -> str:\n",
    "    \"\"\"Create an enumeration of a list of strings.\n",
    "    \n",
    "    Args:\n",
    "        list_of_strings (list): list of strings to enumerate\n",
    "        \n",
    "    Returns:\n",
    "        str: enumeration of the list of strings\n",
    "    \"\"\"\n",
    "    return \"\\n\".join([f\"{i+1}. {string}\" for i, string in enumerate(list_of_strings)])\n",
    "\n",
    "\n",
    "def randomly_select_n_generations_for_a_specific_tool(tool, n: int):\n",
    "    \"\"\"Randomly select n generations for a specific tool.\n",
    "    \n",
    "    Args:\n",
    "        tool (dict): tool to select the generations from\n",
    "        n (int): number of generations to select\n",
    "    \n",
    "    Returns:\n",
    "        list: list of n generations\n",
    "    \"\"\"\n",
    "    generations = tool['dataset']\n",
    "    random.shuffle(generations)\n",
    "    return deepcopy(generations[:n])\n",
    "\n",
    "\n",
    "def randomly_select_n_generations(dataset, n: int):\n",
    "    \"\"\"Randomly select n generations for each tool in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): dataset to select the generations from\n",
    "        n (int): number of generations to select\n",
    "        \n",
    "    Returns:\n",
    "        list: list of n generations for each tool in the dataset\n",
    "    \"\"\"\n",
    "    for tool in dataset:\n",
    "        generations = randomly_select_n_generations_for_a_specific_tool(tool, n)\n",
    "        list_of_generations = [generation['user_request'] for generation in generations]\n",
    "        print(f\"\"\"The tool '{tool['tool_name']}' should {lower_case_first_letter(tool['description'])}'\n",
    "{create_an_enumeration(list_of_generations)}\"\"\")\n",
    "\n",
    "\n",
    "def make_description(dataset_a, dataset_b, n: int = 5, filename: str = \"form.txt\"):\n",
    "    \"\"\"Make a description of the datasets, based on the tools descriptions and on randomly selected generations.\n",
    "    \n",
    "    Args:\n",
    "        dataset_a (list): dataset a\n",
    "        dataset_b (list): dataset b\n",
    "        n (int, optional): number of generations to select for each tool. Defaults to 5.\n",
    "        filename (str, optional): name of the file to write the description in. Defaults to \"form.txt\".\n",
    "    \"\"\"\n",
    "    tools_questions = []\n",
    "    for tool_a, tool_b in zip(dataset_a, dataset_b):\n",
    "        random_generations_a = randomly_select_n_generations_for_a_specific_tool(tool_a, n)\n",
    "        random_generations_b = randomly_select_n_generations_for_a_specific_tool(tool_b, n)\n",
    "        list_of_generations_a = [generation['user_request'] for generation in random_generations_a]\n",
    "        list_of_generations_b = [generation['user_request'] for generation in random_generations_b]\n",
    "        enumerated_generations_a = create_an_enumeration(list_of_generations_a)\n",
    "        enumerated_generations_b = create_an_enumeration(list_of_generations_b)\n",
    "\n",
    "        tools_questions.append(f\"\"\"The tool '{tool_a['tool_name']}' should {lower_case_first_letter(tool_a['description'])}\n",
    "In the dataset a, the following user requests were generated for the tool '{tool_a['tool_name']}':\n",
    "\n",
    "{enumerated_generations_a}\n",
    "\n",
    "In the dataset b, the following user requests were generated for the tool '{tool_a['tool_name']}':\n",
    "\n",
    "{enumerated_generations_b}\n",
    "\"\"\")\n",
    "    with open(filename, 'w') as text_file:\n",
    "        text_file.write(\"\\n\".join(tools_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the datasets from the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "TOOLS_FILE = \"tools/tools.json\"\n",
    "DATASET_FILES_0 = \"datasets/results_prompts_0\"\n",
    "DATASET_FILES_1 = \"datasets/results_prompts_1\"\n",
    "\n",
    "# Open tool json file\n",
    "with open(TOOLS_FILE, 'r') as json_file:\n",
    "    tools = json.load(json_file)\n",
    "\n",
    "# print(list(f\"{DATASET_FILES_0}/{file}\" for file in os.listdir(DATASET_FILES_0)))\n",
    "dataset_files_0 = [f\"{DATASET_FILES_0}/{file}\" for file in os.listdir(DATASET_FILES_0)]\n",
    "dataset_files_1 = [f\"{DATASET_FILES_1}/{file}\" for file in os.listdir(DATASET_FILES_1)]\n",
    "\n",
    "dataset_0 = extract_dataset(dataset_files_0, tools)\n",
    "dataset_1 = extract_dataset(dataset_files_1, tools)\n",
    "\n",
    "make_json_file(dataset_0, f\"{DATASET_FILES_0}.json\")\n",
    "make_json_file(dataset_1, f\"{DATASET_FILES_1}.json\")\n",
    "\n",
    "print(extract_dataset(dataset_files_1, tools) == extract_dataset(dataset_files_0, tools))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the datasets with ROUGE ('built-in' the datasets)\n",
    "### Test Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the way to make people trustworthy is to trust them\n",
      "to make people trustworthy you need to trust them\n",
      "rouge_score(generation, reference) = 0.7058823479584776\n"
     ]
    }
   ],
   "source": [
    "generation = \"to make people trustworthy you need to trust them\"\n",
    "reference = \"the way to make people trustworthy is to trust them\"\n",
    "\n",
    "print(reference)\n",
    "print(generation)\n",
    "\n",
    "print(f\"{rouge_score(generation, reference) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the dataset\n",
    "1. Get a broad and granular view of the datasets ROUGE scores\n",
    "2. Compute the size of the datasets (number of elements, number of elements per class and statistical metrics)\n",
    "\n",
    "### Compare the ROUGE scores of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: detect_object \taverage ROUGE score: 0.38469106173714723\n",
      "Class: enumerate_objects \taverage ROUGE score: 0.3301340027102317\n",
      "Class: navigation \taverage ROUGE score: 0.516528920634861\n",
      "Class: position \taverage ROUGE score: 0.010416666471354169\n",
      "Class: add_face \taverage ROUGE score: 0.05291005201058202\n",
      "Class: remove_face \taverage ROUGE score: 0.06144781029461283\n",
      "Class: look_for_face \taverage ROUGE score: 0.010101009898989903\n",
      "Class: enumerate_individuals \taverage ROUGE score: 0.013935339704892384\n",
      "Class: age_estimation \taverage ROUGE score: 0.15151514904109012\n",
      "Class: gender_estimation \taverage ROUGE score: 0.06593406501567235\n",
      "Class: emotion_estimation \taverage ROUGE score: 0.09256198094665673\n",
      "Class: colors \taverage ROUGE score: 0.32435640436759766\n",
      "Class: object_color \taverage ROUGE score: 0.4510207879933894\n",
      "Class: ocr \taverage ROUGE score: 0.2859504082268971\n",
      "Class: ocr_objects \taverage ROUGE score: 0.2684777295577613\n",
      "Class: money \taverage ROUGE score: 0.17371845877603714\n",
      "Class: environment_description \taverage ROUGE score: 0.36868686421780306\n",
      "Class: environment_question \taverage ROUGE score: 0.006993006777837554\n",
      "Total average ROUGE score: 0.006998783761536105\n"
     ]
    }
   ],
   "source": [
    "print_dataset_mean_rouge(dataset_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: detect_object \taverage ROUGE score: 0.8560846510871253\n",
      "Class: enumerate_objects \taverage ROUGE score: 0.46048647825218103\n",
      "Class: navigation \taverage ROUGE score: 0.5571747043697814\n",
      "Class: position \taverage ROUGE score: 0.03571428526785715\n",
      "Class: add_face \taverage ROUGE score: 0.4015567715959727\n",
      "Class: remove_face \taverage ROUGE score: 0.4032633982902994\n",
      "Class: look_for_face \taverage ROUGE score: 0.37996031254269425\n",
      "Class: enumerate_individuals \taverage ROUGE score: 0.037037036851851855\n",
      "Class: age_estimation \taverage ROUGE score: 0.36381673412765986\n",
      "Class: gender_estimation \taverage ROUGE score: 0.15120772778003222\n",
      "Class: emotion_estimation \taverage ROUGE score: 0.10148336264821496\n",
      "Class: colors \taverage ROUGE score: 0.60030120898732\n",
      "Class: object_color \taverage ROUGE score: 0.7677018583550037\n",
      "Class: ocr \taverage ROUGE score: 0.7867768545116455\n",
      "Class: ocr_objects \taverage ROUGE score: 0.3409951110237474\n",
      "Class: money \taverage ROUGE score: 0.1476967451334499\n",
      "Class: environment_description \taverage ROUGE score: 0.3332644585059275\n",
      "Class: environment_question \taverage ROUGE score: 0.08608058355964912\n",
      "Total average ROUGE score: 0.014968356665693214\n"
     ]
    }
   ],
   "source": [
    "print_dataset_mean_rouge(dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of elements: 510\n",
      "{'detect_object': 22, 'enumerate_objects': 22, 'navigation': 22, 'position': 24, 'add_face': 21, 'remove_face': 66, 'look_for_face': 22, 'enumerate_individuals': 23, 'age_estimation': 58, 'gender_estimation': 23, 'emotion_estimation': 55, 'colors': 21, 'object_color': 22, 'ocr': 22, 'ocr_objects': 22, 'money': 21, 'environment_description': 22, 'environment_question': 22}\n",
      "Mean: 28.333333333333332\n",
      "Median: 22.0\n",
      "Total number of elements: 455\n",
      "{'detect_object': 27, 'enumerate_objects': 22, 'navigation': 23, 'position': 21, 'add_face': 24, 'remove_face': 22, 'look_for_face': 24, 'enumerate_individuals': 27, 'age_estimation': 22, 'gender_estimation': 69, 'emotion_estimation': 22, 'colors': 22, 'object_color': 23, 'ocr': 22, 'ocr_objects': 21, 'money': 21, 'environment_description': 22, 'environment_question': 21}\n",
      "Mean: 25.27777777777778\n",
      "Median: 22.0\n"
     ]
    }
   ],
   "source": [
    "print_dataset_size(dataset_0)\n",
    "print_dataset_size(dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build descriptions of the datasets based on the tools descriptions and randomly selected generated user requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(42)\n",
    "random.seed(None)\n",
    "make_description(dataset_0, dataset_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
